import React, { useEffect, useState, useRef } from "react";
import { useLocation } from "react-router-dom";
import Pitchfinder from "pitchfinder";
import {
  LineChart, Line, XAxis, YAxis, Tooltip, ResponsiveContainer, ReferenceLine
} from "recharts";

export default function Analyze() {
  const { state } = useLocation();
  const file = state?.file;

  const [loading, setLoading] = useState(true);
  const [minHz, setMinHz] = useState(null);
  const [maxHz, setMaxHz] = useState(null);
  const [avgHz, setAvgHz] = useState(null);
  const [data, setData] = useState([]);
  
  const [audioContext, setAudioContext] = useState(null);
  const [audioBuffer, setAudioBuffer] = useState(null);
  const [sourceNode, setSourceNode] = useState(null);

  const [currentTime, setCurrentTime] = useState(0); 
  const [isPlaying, setIsPlaying] = useState(false);

  // ì• ë‹ˆë©”ì´ì…˜ ë£¨í”„ ì œì–´ìš© Ref ì¶”ê°€
  const requestRef = useRef(); 
  const isPlayingRef = useRef(false); // ë£¨í”„ ì•ˆì—ì„œ ì¦‰ì‹œ ìƒíƒœ í™•ì¸ìš©

  useEffect(() => {
    if (!file) return;

    const reader = new FileReader();

    reader.onload = async (e) => {
      try {
        const arrayBuffer = e.target.result;
        
        // 1. ì¼ë‹¨ ì˜¤ë””ì˜¤ ë””ì½”ë”© (ì›ë³¸ ë°ì´í„°)
        const tempContext = new (window.AudioContext || window.webkitAudioContext)();
        const originalBuffer = await tempContext.decodeAudioData(arrayBuffer);

        // ----------------------------------------------------------------
        // ğŸŒªï¸ [í•µì‹¬] ê³ ì£¼íŒŒ ì œê±° í•„í„°ë§ (Low-Pass Filter)
        // ë¶„ì„ ì „ì— 5000Hz ì´ìƒì˜ ì†Œë¦¬ë¥¼ ë¬¼ë¦¬ì ìœ¼ë¡œ ì‚­ì œí•´ë²„ë¦¼
        // ----------------------------------------------------------------
        
        // ì˜¤í”„ë¼ì¸ ì»¨í…ìŠ¤íŠ¸ ìƒì„± (ì†Œë¦¬ë¥¼ ë‚´ì§€ ì•Šê³  ê³ ì†ìœ¼ë¡œ ì²˜ë¦¬í•˜ëŠ” ì „ìš© ê³µê°„)
        const offlineCtx = new OfflineAudioContext(
          1, // ëª¨ë…¸ ì±„ë„ë¡œ ë³€í™˜ (ë¶„ì„ì—” ìŠ¤í…Œë ˆì˜¤ í•„ìš” ì—†ìŒ)
          originalBuffer.length,
          originalBuffer.sampleRate
        );

        // ì†ŒìŠ¤ ìƒì„±
        const source = offlineCtx.createBufferSource();
        source.buffer = originalBuffer;

        // í•„í„° ìƒì„± (Lowpass, 5000Hz)
        // -> ì´ëŸ¬ë©´ 20,000Hz ì¡ìŒì´ ì‹¹ ì‚¬ë¼ì ¸ì„œ YIN ì•Œê³ ë¦¬ì¦˜ì´ í—·ê°ˆë¦¬ì§€ ì•ŠìŒ
        const filter = offlineCtx.createBiquadFilter();
        filter.type = "lowpass";
        filter.frequency.value = 5000; // í”¼ì•„ë…¸ ìµœê³ ìŒ(ì•½ 4186Hz)ë³´ë‹¤ ì‚´ì§ ë†’ê²Œ

        // ì—°ê²°: ì†ŒìŠ¤ -> í•„í„° -> ëª©ì ì§€
        source.connect(filter);
        filter.connect(offlineCtx.destination);
        source.start();

        // ë Œë”ë§ ì‹œì‘ (í•„í„° ë¨¹ì¸ ê¹¨ë—í•œ ì˜¤ë””ì˜¤ ë²„í¼ ìƒì„±)
        const filteredBuffer = await offlineCtx.startRendering();
        
        // ì´ì œ 'ê¹¨ë—í•´ì§„' ë°ì´í„°ë¡œ ë¶„ì„ ì‹œì‘
        const channelData = filteredBuffer.getChannelData(0);

        // ----------------------------------------------------------------
        // ì•„ë˜ëŠ” ê¸°ì¡´ ë¡œì§ê³¼ ë™ì¼ (ë‹¨, audioContextëŠ” ì¬ìƒìš©ìœ¼ë¡œ ë”°ë¡œ ì €ì¥)
        // ----------------------------------------------------------------
        
        // ì¬ìƒì„ ìœ„í•œ ë©”ì¸ ì»¨í…ìŠ¤íŠ¸ ì €ì¥ (í•„í„°ë§ ëœ ê±° ë§ê³  ì›ë³¸ì„ ì¬ìƒí•´ì•¼ ë“£ê¸° ì¢‹ìŒ)
        setAudioBuffer(originalBuffer); 
        setAudioContext(tempContext);

        // Pitchfinder ì„¤ì •
        const detectPitch = Pitchfinder.YIN({
          sampleRate: offlineCtx.sampleRate,
          threshold: 0.05,
        });

        const frameSize = 2048; 
        const rawResults = [];

        // ë³¼ë¥¨ ì²´í¬ìš© (ìƒëŒ€ì  ê¸°ì¤€)
        let globalMaxRms = 0;
        for (let i = 0; i < channelData.length; i += 1000) {
            const val = Math.abs(channelData[i]);
            if (val > globalMaxRms) globalMaxRms = val;
        }
        const noiseThreshold = globalMaxRms * 0.08; 

        // ë¶„ì„ ë£¨í”„
        for (let i = 0; i < channelData.length; i += frameSize) {
          const frame = channelData.slice(i, i + frameSize);
          
          const rms = Math.sqrt(frame.reduce((sum, val) => sum + (val * val), 0) / frame.length);
          const freq = detectPitch(frame);
          const time = parseFloat((i / offlineCtx.sampleRate).toFixed(2));

          // 5000 í•„í„°ëŠ” ì—¬ê¸°ì„œë„ ìœ ì§€ (ì´ì¤‘ ì•ˆì „ì¥ì¹˜)
          if (freq && freq > 25 && freq < 5000) {
            rawResults.push({ time, hz: freq, rms });
          } else {
            // ì›ë˜ 20000Hzê°€ ì°íˆë˜ êµ¬ê°„ì´ ì´ì œëŠ” 
            // í•„í„° ë•ë¶„ì— ì œëŒ€ë¡œ ëœ ë‚®ì€ ì£¼íŒŒìˆ˜(í˜¹ì€ 0)ë¡œ ì¡í ê²ƒì„
            rawResults.push({ time, hz: 0, rms });
          }
        }

        if (rawResults.length === 0) {
          alert("í”¼ì¹˜ë¥¼ ê²€ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.");
          setLoading(false);
          return;
        }

        // í•„í„°ë§ ë° í†µê³„ ì²˜ë¦¬ (ê¸°ì¡´ê³¼ ë™ì¼)
        const filteredData = applySmartFilters(rawResults, noiseThreshold);
        const smoothedData = fillShortGaps(filteredData, 12); 

        // ... (í†µê³„ ê³„ì‚° ë¡œì§)
        const freqs = smoothedData.map((v) => v.hz).filter(hz => hz > 0);
        if (freqs.length > 0) {
            const min = Math.min(...freqs).toFixed(1);
            const max = Math.max(...freqs).toFixed(1);
            const avg = (freqs.reduce((a, b) => a + b, 0) / freqs.length).toFixed(1);
            setMinHz(min);
            setMaxHz(max);
            setAvgHz(avg);
        } else {
            setMinHz(0); setMaxHz(0); setAvgHz(0);
        }

        setData(smoothedData);

      } catch (err) {
        console.error("ì˜¤ë¥˜:", err);
      } finally {
        setLoading(false);
      }
    };

    reader.readAsArrayBuffer(file);
  }, [file]);

  // --- [í•µì‹¬ í•¨ìˆ˜ 1] ìŠ¤ë§ˆíŠ¸ í•„í„° ---
  const applySmartFilters = (data, threshold) => {
    let processed = data.map(d => ({ ...d }));

    // ê³ ì£¼íŒŒ ë…¸ì´ì¦ˆ ì œê±°
    processed = processed.map(p => {
      if (p.hz > 1500 && p.rms < threshold) return { ...p, hz: 0 };
      return p;
    });

    // ë¯¸ë””ì–¸ í•„í„° (íŠ€ëŠ” ê°’ ì œê±°)
    const windowSize = 100; 
    const half = Math.floor(windowSize / 2);
    
    const medianFiltered = processed.map((item, i, arr) => {
      if (i < half || i >= arr.length - half) return item;
      if (item.hz === 0) return item;

      const windowVals = [];
      for (let j = -half; j <= half; j++) {
        if (arr[i+j].hz > 0) windowVals.push(arr[i+j].hz);
      }

      if (windowVals.length < 3) return item;

      windowVals.sort((a, b) => a - b);
      const median = windowVals[Math.floor(windowVals.length / 2)];

      if (Math.abs(item.hz - median) > median * 0.5) {
         return { ...item, hz: median }; 
      }
      return item;
    });

    return medianFiltered;
  };

  // --- [í•µì‹¬ í•¨ìˆ˜ 2] ëŠê¹€ ë³´ì • ---
  const fillShortGaps = (data, maxGapFrame) => {
    const processed = data.map(item => ({ ...item }));
    let lastValidHz = null;
    let gapIndices = [];

    for (let i = 0; i < processed.length; i++) {
      const currentHz = processed[i].hz;
      if (currentHz && currentHz > 0) {
        if (gapIndices.length > 0) {
          if (gapIndices.length <= maxGapFrame && lastValidHz !== null) {
            for (const index of gapIndices) processed[index].hz = lastValidHz;
          }
          gapIndices = [];
        }
        lastValidHz = currentHz;
      } else {
        gapIndices.push(i);
      }
    }
    return processed;
  };

  const play = () => {
    if (!audioContext || !audioBuffer) return;
    
    // ì´ë¯¸ ì¬ìƒ ì¤‘ì´ë©´ ì¤‘ë³µ ì‹¤í–‰ ë°©ì§€
    if (isPlayingRef.current) return;

    if (sourceNode) sourceNode.stop();

    const newSource = audioContext.createBufferSource();
    newSource.buffer = audioBuffer;
    newSource.connect(audioContext.destination);
    
    // í˜„ì¬ ì‹œì ë¶€í„° ì¬ìƒ
    newSource.start(0, currentTime);

    // ì¬ìƒ ì‹œì‘ ì‹œê°„ ê³„ì‚°
    const startAt = audioContext.currentTime - currentTime;

    // ìƒíƒœ ë™ê¸°í™”
    setIsPlaying(true);
    isPlayingRef.current = true; // Refë„ trueë¡œ

    const update = () => {
      // ë£¨í”„ ì•ˆì—ì„œëŠ” Refë¥¼ ë°”ë¼ë´ì•¼ ë©ˆì¶”ì§€ ì•ŠìŒ
      if (!isPlayingRef.current) return;

      const t = audioContext.currentTime - startAt;
      
      // ë²„í¼ ê¸¸ì´ ë„˜ì–´ê°€ë©´ ì •ì§€
      if (t >= audioBuffer.duration) {
        pause();
        setCurrentTime(0); // ëë‚˜ë©´ 0ì´ˆë¡œ
        return;
      }

      setCurrentTime(t);
      requestRef.current = requestAnimationFrame(update);
    };

    requestRef.current = requestAnimationFrame(update);
    setSourceNode(newSource);
  };

  const pause = () => {
    if (sourceNode) {
      try {
        sourceNode.stop();
      } catch (e) {
        // ì´ë¯¸ ë©ˆì¶˜ ê²½ìš° ë¬´ì‹œ
      }
    }
    
    // ë£¨í”„ ì·¨ì†Œ
    if (requestRef.current) {
      cancelAnimationFrame(requestRef.current);
    }

    setIsPlaying(false);
    isPlayingRef.current = false; // Ref falseë¡œ ë³€ê²½í•˜ì—¬ ë£¨í”„ íƒˆì¶œ
  };

  // ì»´í¬ë„ŒíŠ¸ê°€ ì‚¬ë¼ì§ˆ ë•Œ(ì–¸ë§ˆìš´íŠ¸) ì •ë¦¬
  useEffect(() => {
    return () => {
      if (requestRef.current) cancelAnimationFrame(requestRef.current);
      if (sourceNode) {
        try { sourceNode.stop(); } catch(e) {}
      }
    };
  }, []); // ì˜ì¡´ì„± ë°°ì—´ ë¹„ì›€

  // ì°¨íŠ¸ ë°ì´í„° ë³€í™˜ (0 -> null)
  const chartData = data.map((d) => ({
    ...d,
    hz: d.hz <= 0 ? null : d.hz,
  }));

  // --- [UI ë Œë”ë§] ---
  return (
    <div style={styles.container}>
      {/* 1. ì œëª© ë° íŒŒì¼ëª… */}
      <h1 style={styles.title}>ğŸ“Š File Pitch Analysis</h1>
      {file && <p style={styles.filename}>ë¶„ì„ íŒŒì¼: <b>{file.name}</b></p>}

      {/* 2. ë¡œë”©ë°” */}
      {loading && (
        <div style={styles.loadingBox}>
          <div className="spinner" style={styles.spinner}></div>
          <p style={styles.loadingText}>ğŸ”„ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤â€¦ ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”.</p>
        </div>
      )}

      {/* 3. ë¶„ì„ ê²°ê³¼ ë°•ìŠ¤ */}
      {!loading && minHz && (
        <div style={styles.infoBox}>
          <p>ìµœì € Hz: {minHz}</p>
          <p>ìµœê³  Hz: {maxHz}</p>
          <p>í‰ê·  Hz: {avgHz}</p>
        </div>
      )}

      {/* 4. ì¬ìƒ ì»¨íŠ¸ë¡¤ ë° ê·¸ë˜í”„ */}
      {!loading && data.length > 0 && (
        <>
          <div style={{ marginBottom: "20px" }}>
            {!isPlaying ? (
              <button onClick={play} style={styles.button}>â–¶ ì¬ìƒ</button>
            ) : (
              <button onClick={pause} style={styles.button}>â¸ ì¼ì‹œì •ì§€</button>
            )}
          </div>
          
          <ResponsiveContainer width="95%" height={400}>
            <LineChart 
              data={chartData}
              onClick={(e) => {
                if (e && e.activeLabel) {
                  const clickedTime = parseFloat(e.activeLabel);
                  setCurrentTime(clickedTime);
                  // ì¬ìƒ ì¤‘ ì´ë™ ì‹œ ë°”ë¡œ ë°˜ì˜ì„ ìœ„í•´
                  if (isPlaying) {
                     pause(); // ì ê¹ ë©ˆì·„ë‹¤ ë‹¤ì‹œ ì¬ìƒí•˜ê±°ë‚˜, UXì— ë”°ë¼ ê²°ì •
                     // ì—¬ê¸°ì„œëŠ” ê°„ë‹¨íˆ ë©ˆì¶¤ ì²˜ë¦¬ (ì‚¬ìš©ìê°€ ë‹¤ì‹œ ì¬ìƒ ëˆ„ë¥´ê²Œ)
                  }
                }
              }}
            >
              <YAxis 
                  domain={['auto', 'auto']} 
                  tickCount={10} 
                  width={40}
              />
              <XAxis dataKey="time" />
              <Tooltip />
              {/* 6. ë¹¨ê°„ ì„ : xê°’ì— ìˆ«ìë¥¼ ê·¸ëŒ€ë¡œ ë„£ì–´ì•¼ ì •í™•í•˜ê²Œ ë§¤ì¹­ë¨ */}
              <ReferenceLine 
                x={currentTime} 
                stroke="red" 
                strokeWidth={2}
                isFront={true} // ë¼ì¸ì´ ë°ì´í„°ë³´ë‹¤ ì•ì— ì˜¤ê²Œ
                ifOverflow="visible" // ì°¨íŠ¸ ë°–ìœ¼ë¡œ ë‚˜ê°€ë„ ë³´ì´ê²Œ (ì•ˆì „ì¥ì¹˜)
              />
              <Line 
                type="monotone" 
                dataKey="hz" 
                stroke="#FFD940" 
                dot={false} 
                connectNulls={false} 
                isAnimationActive={false}
              />
            </LineChart>
          </ResponsiveContainer>
        </>
      )}
    </div>
  );
}

const styles = {
  container: {
    padding: "50px",
    textAlign: "center",
    color: "#fff",
    background: "linear-gradient(135deg, #0D1B3D, #102C5B)",
    minHeight: "100vh",
  },
  title: { fontSize: "36px", marginBottom: "10px" },
  filename: { fontSize: "18px", opacity: 0.9, marginBottom: "30px" },
  loadingBox: { marginTop: "60px", marginBottom: "40px" },
  spinner: {
    margin: "0 auto",
    border: "6px solid rgba(255,255,255,0.3)",
    borderTop: "6px solid #FFD940",
    borderRadius: "50%",
    width: "50px",
    height: "50px",
    animation: "spin 1s linear infinite",
  },
  loadingText: { marginTop: "15px", fontSize: "18px", opacity: 0.9 },
  infoBox: {
    background: "rgba(255,255,255,0.1)",
    padding: "20px",
    borderRadius: "10px",
    display: "inline-block",
    marginBottom: "30px",
    fontSize: "18px",
    lineHeight: "1.6",
  },
  button: {
    padding: "10px 20px",
    fontSize: "16px",
    cursor: "pointer",
    borderRadius: "5px",
    border: "none",
    backgroundColor: "#FFD940",
    color: "#0D1B3D",
    fontWeight: "bold"
  }
};

const styleSheet = document.styleSheets[0];
try {
    styleSheet.insertRule(`
    @keyframes spin {
        0% { transform: rotate(0deg); }
        100% { transform: rotate(360deg); }
    }
    `, styleSheet.cssRules.length);
} catch (e) {}